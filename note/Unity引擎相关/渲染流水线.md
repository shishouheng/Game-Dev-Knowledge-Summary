
# 一、渲染流水线的概念

unity的渲染流水线是一个复杂的渲染过程，负责将游戏中的3D模型、纹理、光照和其他效果转换为最终在屏幕上显示的2D像素图像。这个过程包括许多步骤，可以分为以下几个主要阶段：
- 应用阶段：在这个阶段Unity会根据场景的设置和脚本代码来准备渲染所需的数据。这包括确定哪些对象需要被渲染，以及它们在世界空间中的位置和方向
- 几何阶段：在这个阶段Unity会处理每个需要渲染的对象的几何数据。包括将对象的顶点数据从模型空间转到裁剪空间。此外还会进行光照计算和其他顶点级别的操作
- 光栅化阶段：在这个阶段，Unity会将处理过的几何数据转换为屏幕上的像素。包括将顶点数据从摄像机空间转换到屏幕空间，以及根据深度测试、透明度测试来确定每个像素的最终颜色。

# 二、坐标系转换

一个3D模型从外部导入Unity并最终渲染到屏幕上时会经过三次坐标系转换，分别是
`模型空间——世界空间——观察空间——裁剪空间`

## 1.模型变换
模型空间需要向世界空间转换的原因是建模时模型的坐标信息都是在模型空间下的表示，当模型被放到Unity中的世界时，就需要用unity中的世界坐标来表示它的坐标信息，所以模型上的每个顶点，都必须完成到世界空间的转换
```c#
struct appdata
{
	//模型空间的位置坐标，由Render提供，作为顶点着色器的输入
	float4 vertex:POSITION;
}
```


## 2.观察变换（视图变换）
由于我们看到的渲染图形都是由摄像机决定的，为了方便后续裁剪投影等操作，还需要将模型的世界空间坐标转换为观察空间坐标
观察空间就是指以相机为坐标原点，相机的局部坐标轴为坐标轴的坐标系


## 3.投影变换
为了方便后续的缩放，还需要将模型从观察空间坐标系转换为裁剪空间坐标系，即NDC（立方体空间坐标），本质就是对平截头体进行缩放，使近裁剪面和远裁剪面编程正方形，w坐标表示裁剪范围

```c#
struct a2v
 {
 float4 vertex:POSITION;
 float2 uv:TEXCOORD0;
 };
 struct v2f
 {
 float4 pos : SV_POSITION;
 float2 uv:TEXCOORD;//纹理坐标
 };
 v2f vert (a2v v)
 {
 v2f o;
 //UNITY_MATRIX_M 从模型空间到世界空间
 //UNITY_MATRIX_V 从世界空间到观察空间
 //UNITY_MATRIX_P 从观察空间到裁剪空间
 //UNITY_MATRIX_MVP 直接从模型空间转换到裁剪空间
 //SV_POSITION 输出一个裁剪空间的坐标 经过三次转换才能正常显示模型
 o.pos=mul(UNITY_MATRIX_M,v.vertex);
 o.pos=mul(UNITY_MATRIX_V,o.pos);
 o.pos=mul(UNITY_MATRIX_P,o.pos);
 o.uv=TRANSFORM_TEX(v.uv,_MainTex);
 return o;
 }
```


## 4.UnityCG.cginc

这是Unity内置的一个着色器库文件，包含了常用的着色器函数和常量定义

结构体
```c#
appdata_base: 顶点位置 顶点法线 第一纹理坐标
appdata_tan: 顶点位置 顶点法线 顶点切线 第一纹理坐标
appdata_full: 顶点位置 顶点法线 顶点切线 四组纹理坐标 顶点颜色
appdata_img: 顶点位置 纹理坐标
v2f_img:裁剪空间的顶点坐标 纹理坐标
```

函数
```c#
float3 WorldSpaceViewDir 输入一个模型空间的顶点位置 返回世界空间下该点到相机的
观察方向
float3 ObjSpaceViewDir 输入一个模型空间的顶点位置 返回模型空间下该点到相机的观
察方向
float3 WorldSpaceLightDir 输入一个模型空间的顶点位置 返回世界空间下该点到光源的
光照方向
float3 ObjSpaceLightDir 输入一个模型空间的顶点位置 返回模型空间下该点到光源的光
照方向
float3 UnityObjectToWorldDir 把方向向量从模型空间变换到世界空间
float3 UnityWorldToObjectDir 把方向向量从世界空间变换到模型空间
float3 UnityObjectToWorldNormal 把法线向量从模型空间转换为世界空间 归一化
UnityObjectToClipPos 将顶点坐标转换为裁剪空间坐标
```


# 三、渲染流水线

渲染流程的3个阶段分别是：
- 1.应用阶段：由cpu负责，这一阶段主要由开发者准备好摄像机、模型和光源等数据，并做好相应的剔除工作，并设置好材质、纹理、shader等渲染状态，最后输出渲染所需要的图元
- 2.几何阶段：由gpu负责，把上一阶段传递来的图元进行逐顶点，逐多边形的操作，并把顶点坐标从模型空间经过一系列转换最终到屏幕空间。同时输出屏幕空间的二维顶点坐标、顶点深度、顶点颜色等数据，然后交给光栅器处理
- 3.光栅化阶段：由gpu负责，对上个阶段的逐顶点数据进行插值，再做逐像素处理，决定哪些像素会被绘制，哪些会被剔除，并计算它们的颜色和光照

![[shader pipeline.png]]
![](https://github.com/shishouheng/Unity-learning/blob/main/images/shader%20pipeline.png)
在渲染流水线的过程中，cpu和gpu都担任着不同的工作，其中：

cpu的工作是把数据从硬盘加载到系统内存中，然后把内存中的网格、纹理、顶点位置、颜色、法线、纹理坐标这些数据加载到显存中。
并调用一次DrawCall指向一个要被渲染的图元列表，通知GPU按照以上设置的数据和状态来进行渲染
cpu准备渲染数据是个很漫长的过程，而gpu渲染很快，如果drawcall过于频繁，cpu会一直处于准备数据的状态，而gpu处于等待渲染的状态，所以每次发送drawcall都要尽可能多的发送数据给GPU，减少drawcall从而达到快速渲染的效果。


## 1.完整过程

可以用十个字概括三个阶段所经过的操作：顶曲几裁屏 三三片逐屏


![[shade pipeline complete process.png]]
![](https://github.com/shishouheng/Unity-learning/blob/main/images/shade%20pipeline%20complete%20process.png)
绿色：可编程控制部分
黄色：可配置，但是不可编程
蓝色：GPU固定实现，不可控制

在整个流水线中，顶点着色器必须实现，片元着色器可选择是否需要实现

顶点着色器：处理单个顶点数据，开发者需要在顶点着色器里完成坐标系转换，把顶点从模型空间转换到裁剪空间，最终得到归一化坐标，还会进行逐顶点光照，并准备好后续阶段需要的其他数据，比如纹理坐标、顶点颜色等

曲面细分着色器：细分图元

几何着色器：执行图元的着色操作，产生更多图元

裁剪：之前阶段所得到的是NDC立方体空间，在OpenGL中这个空间大小是（-1，-1，-1）到（1，1，1）；在DirectX中这个空间大小是（0，0，0）到
（1，1，1），完全在空间内的会保留，完全在空间外的会被抛弃，一半在空间内一半在空间外的会将空间外的裁剪，最终得到的是我们视野能看到的部分

屏幕映射：即将三维转换为二维，经过裁剪后的NDC坐标，依然是三维坐标，屏幕映射的任务就是把每个图元的x，y坐标转换到屏幕坐标系，通过缩放确定图元的屏幕坐标位置。然后由屏幕坐标和z坐标构成窗口坐标系。（OpenGL会以屏幕左下角为最小坐标，DirectX会以左上角为最小坐标）

三角形设置：构建三角形网格数据，通过上个阶段输出的三角形顶点信息，计算出三角形的边界从而构建三角形网格数据

三角形遍历：检测每个像素被哪个三角形所覆盖，从而生成片元，三角的三个顶点会对覆盖的每个像素的数据进行插值，比如深度、坐标、颜色

片元着色器：在三角形遍历后生成的片元的所有数据在这个阶段会通过算法利用数据生成或计算片元的颜色，然后通过纹理采样或逐像素光照等渲染技术输出片元的颜色，这个阶段也会进行透明度测试

逐片元操作：经过模板测试和深度测试后决定好了每个片元的可见性，测试通过的片元要和已存在颜色缓冲区的颜色进行合并，开启混合的就进行混合，未开启混合的则覆盖

屏幕图像：经过以上计算，内容就会在屏幕上了，GPU采用多重缓冲机制，渲染发生在后置缓冲，渲染结束后会切换到前置缓冲来显示


## 2.三大测试

在渲染流水线的片元着色器阶段会进行透明度测试，在逐片元操作时会进行深度测试和模板测试。这些测试是用于控制渲染顺序和可见性的

### 2.1 透明度测试

透明度测试是在片元着色器阶段进行的测试。通常会根据片元的alpha值与一个阈值进行比较，如果透明度小于阈值，则片元会被丢弃，否则保留。透明度测试可以用于实现物体的透明效果。

### 2.2模板测试

模板测试是在逐片元阶段操作进行的测试，用于根据像素的特定属性来控制像素的可见性。通过与模板缓冲区中的值进行比较来决定是否保留像素。根据比较结果，可以执行不同的操作，如写入模板缓冲区、丢弃像素等。

### 2.3 深度测试

深度测试也是在逐片元操作阶段进行的一种测试（在模板测试通过之后才会进行）。深度测试通过比较当当前像素的深度值与深度缓冲区中的值来决定是否保留像素。如果当前像素的深度值小于深度缓冲区中的值，则保留像素，否则丢弃。

物体的深度是根据像素点在3D世界中距离相机的远近决定的，距离相近越近，深度越小，Z值越小

在进行深度测试的时候，会先在深度缓存中存储着要绘制在屏幕上的像素点的深度值，当开启深度缓冲区绘制像素之前，OpenGL会先把像素的深度值和该像素在深度缓存中的深度值进行比较。
如果新像素深度值<深度缓存深度值  则新像素会取代原先
	反之说明新像素被遮挡，颜色与深度都将被丢弃


如果未开启深度测试，当先渲染距离较近的物体，再渲染距离较远的物体时，则距离远的物体会因为后绘制而覆盖距离进的物体，效果不对
而开启深度测试后，渲染物体的顺序就不是唯一的判断依据，可以保证所有的物体会根据与摄像机的远近而进行正确的显示